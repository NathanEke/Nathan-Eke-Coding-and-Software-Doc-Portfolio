{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f55b2f",
   "metadata": {},
   "source": [
    "# Midterm Project\n",
    "\n",
    "<font size=\"4\" color=\"red\">___/100pts</font>\n",
    "\n",
    "### Your Name:\n",
    "\n",
    "### 1. Write a brief description of the texts you used for the midterm.\n",
    "(Write your summary here...)\n",
    "\n",
    "### 2. A brief Summary of your findings\n",
    "(Write your summary here...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c4025",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "**First, review the midterm assignment description on Canvas carefully. The follow the instructions below to write your code.**\n",
    "\n",
    "\n",
    "### Before you start writing your code\n",
    "- This notebook provides you with a template for your medterm project based on the functions included in Unit 6 of the textbook. Make sure that you have a good understanding of the code introduced in Unit 6.\n",
    "\n",
    "- Create a corpus according to the instructions given in the assignment page on Canvas. Make sure to create your corpus in the folder where this notbook is saved.\n",
    "\n",
    "-  Notice that the assignment description asks you to calcuate 6 items, but functions to calculrate 2 of them are already provided in this template (`get_ttr` and `count_words`).\n",
    "\n",
    "\n",
    "### Step 1.  Write a program that computes the following items for each document.\n",
    "\n",
    "- An average word length (i.e., number of characters in a word)\n",
    "- The top 10 most frequently used words (excluding function words)\n",
    "- The top 10 most frequently used bigrams, and trigrams (bigrams and trigrams should include function words)\n",
    "\n",
    "This program consists of multiple functions. The main function is `analyze_a_file` defined below. This function calls 6 functions that calculate the followin gitems.\n",
    "\n",
    "First, you should write functions to calculate the items listed above. **Use the code cells provided below for these functions.** For the 3rd item, you will need to write 2 functions, for bigrams and trigrams.\n",
    "\n",
    "After you have written and tested these functions individually, add these functions to `analyze_a_file`.\n",
    "\n",
    "### Step 2.  Using the function you wrote for Step 1, write a function that computes the following items for each group\n",
    "\n",
    "- An average word length\n",
    "- The top 10 most frequently used words (excluding function words)\n",
    "- The top 10 most frequently used bigrams and trigrams. (bigrams and trigrams should include function words)\n",
    "\n",
    "This program also consists of multiple functions, and the main function is `analyze_a_corpus` defined below. Study `analyze_a_corpus` and `save_results` carefully first. Then, modify these functions to complete the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec77a5c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "203ab45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank,', 'and', 'of', 'having', 'nothing', 'to', 'do:', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading,', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it,', '`and', 'what', 'is', 'the', 'use', 'of', 'a', \"book,'\", 'thought', 'Alice', '`without', 'pictures', 'or', \"conversation?'\"]\n"
     ]
    }
   ],
   "source": [
    "def make_word_list(fpath):\n",
    "    \"\"\"\n",
    "    This function takes a fpath as its argument, read the text from the file,\n",
    "    split (tokenize) the text into a list of words, and return the list.\n",
    "    \"\"\"\n",
    "    with open(fpath, errors=\"ignore\") as fin: # Open 'file_path', and create a file handler: 'fin'\n",
    "        text  = fin.read()                    # Read the entire content of the file.\n",
    "        words = text.split()                  # Create a list of words.\n",
    "    return words                              # Return 'words'.\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e263cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "def count_words(list_of_words):\n",
    "    \"\"\"\n",
    "    This function takes a list of strings as its argument, and returns the total\n",
    "    number of strings in the list.\n",
    "    \"\"\"\n",
    "    count = len(list_of_words)\n",
    "    return count\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "count = count_words(words)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b915daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "---\n",
      "0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "def get_ttr(list_of_words):\n",
    "    \"\"\"\n",
    "    This function takes a tokenized text (list of words) as its argument, and returns\n",
    "    the type token ratio of the text.\n",
    "    \"\"\"\n",
    "    unique_words = []\n",
    "    \n",
    "    # Create a list of unique words\n",
    "    for word in list_of_words:\n",
    "        if word not in unique_words:            # If 'word' is not in 'unique_words',\n",
    "            unique_words.append(word)           # Append 'word' to 'unique_words'.\n",
    "            \n",
    "    # Calculate the TTR (divide the total # of unique words by the total # of words)    \n",
    "    ttr = len(unique_words)/len(list_of_words)\n",
    "    return ttr\n",
    "\n",
    "# Simple Test\n",
    "ttr = get_ttr([\"dog\", \"dog\", \"cat\"])  # 2 types, 3 tokens. ttr = 2/3\n",
    "print(ttr)\n",
    "print(\"---\")\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "ttr = get_ttr(words)\n",
    "print(ttr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62118aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# An average word length in a file (i.e., average number of characters in a word)\n",
    "def get_average_word_length(list_of_words):\n",
    "\n",
    "    # write your code here\n",
    "    pass # delete this line\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "average = get_average_word_length(words)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5516ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# The top 10 most frequently used words (excluding function words)\n",
    "def get_frequent_words(list_of_words):\n",
    "\n",
    "    # write your code here\n",
    "    pass # delete this line\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "frequent_words = get_frequent_words(words)\n",
    "print(frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fe5417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# The top 10 most frequently used bigrams, and trigrams (bigrams and trigrams should include function words)\n",
    "def get_bigrams(list_of_words):\n",
    "\n",
    "    # write your code here\n",
    "    pass # delete this line\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "bigrams = get_bigrams(words)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f824ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top 10 most frequently used bigrams, and trigrams (bigrams and trigrams should include function words)\n",
    "def get_trigrams(list_of_words):\n",
    "\n",
    "    # write your code here\n",
    "    pass # delete this line\n",
    "\n",
    "# Test\n",
    "words = make_word_list(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "trigrams = get_trigrams(words)\n",
    "print(trigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1a57b",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## analyze_a_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b8ef8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'filename': 'alices_adventures_in_wonderland_p1.txt',\n",
      "    'num_words': 57,\n",
      "    'ttr': 0.7719298245614035}\n",
      "---\n",
      "['Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank,', 'and', 'of', 'having', 'nothing', 'to', 'do:', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading,', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it,', '`and', 'what', 'is', 'the', 'use', 'of', 'a', \"book,'\", 'thought', 'Alice', '`without', 'pictures', 'or', \"conversation?'\"]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pprint                              \n",
    "pp = pprint.PrettyPrinter(indent=4)  \n",
    "\n",
    "def analyze_a_file(in_file_path):\n",
    "    \"\"\"\n",
    "    This function takes a file name path as an argument, and analyzes the content\n",
    "    of the file, and returns (1) the results in a dictionary and (2) the list of words\n",
    "    in the file.\n",
    "    \"\"\"\n",
    "    fpath = pathlib.Path(in_file_path)             # Create a filepath object for 'in_file_path'\n",
    "    list_of_words = make_word_list(in_file_path)   # Create a list of words in the file.\n",
    "    num_words = count_words(list_of_words)         # Count the total # of words in the file.\n",
    "    ttr = get_ttr(list_of_words)\n",
    "    \n",
    "    results = dict()\n",
    "    results['filename'] = fpath.name\n",
    "    results['num_words'] = num_words\n",
    "    results['ttr'] = ttr\n",
    "    \n",
    "    # NEW: Notice that this function returns 2 items.\n",
    "    return results, list_of_words\n",
    "\n",
    "# Test\n",
    "res, words = analyze_a_file(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "pp.pprint(res)\n",
    "print(\"---\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedd923e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## save_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55926427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check test.csv in Excel or Numbers (Mac OS)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pprint                              \n",
    "pp = pprint.PrettyPrinter(indent=4)  \n",
    "\n",
    "def save_results(list_of_results, corpus_results, csv_fpath):\n",
    "    \"\"\"\n",
    "    This function saves the results of a text analysis into a CSV file. You may extend\n",
    "    this function to write more results to the file.\n",
    "    \"\"\"\n",
    "    is_header = True\n",
    "    with open(csv_fpath, 'w') as fout:         # Open 'csv_path'.\n",
    "        writer = csv.writer(fout)              # Create a csv writer object.\n",
    "        \n",
    "        for results in list_of_results:        # For each set of results in 'list_of_results'.\n",
    "            if is_header:\n",
    "                header_row = results.keys()    # Create a list of header items.\n",
    "                writer.writerow(header_row)    # Write the hader items.            \n",
    "                is_header = False\n",
    "            row = results.values()\n",
    "            writer.writerow(row)               # Write the values.\n",
    "\n",
    "        row = corpus_results.values()          # NEW - Add a row for the group (corpus_results)\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Test\n",
    "# Create a simple list of results for testing\n",
    "res1, words = analyze_a_file(\"test/corpus/alices_adventures_in_wonderland_p1.txt\")\n",
    "res2, words = analyze_a_file(\"test/corpus/around_the_world_in_80_days_p1.txt\")\n",
    "res_lst = [res1, res2]         # make a simple list of results with 2 dictionaries\n",
    "\n",
    "# Create a simple corpus result data for testing\n",
    "corpus_results = dict()\n",
    "corpus_results['folder'] = \"test_folder\"\n",
    "corpus_results['num_words'] = 123\n",
    "corpus_results['ttr'] = 0.5\n",
    "\n",
    "save_results(res_lst, corpus_results, \"test/results.csv\")\n",
    "print(\"Check test.csv in Excel or Numbers (Mac OS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b49372",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### anayze_a_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d410c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are stored in test/results.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "def analyze_a_corpus(folder, csv_fpath):\n",
    "    \"\"\"\n",
    "    This function takes a folder as an argument, and analyzes all the text files \n",
    "    in the folder, then writes the results in a CSV file.\n",
    "    \"\"\"\n",
    "    list_of_words = list()                     # Initialize a list that holds all the words in the corpus\n",
    "    list_of_results = list()                   # Initialize a list that holds all the results\n",
    "    file_count = 0\n",
    "    \n",
    "    folder_path = pathlib.Path(folder)         # Make a path object for the folder 'folder'\n",
    "    files = folder_path.glob('*.txt')          # List all the files in the folder.\n",
    "\n",
    "    # Analyze each file in the folder.\n",
    "    for file_path in files:           \n",
    "\n",
    "        results, words_in_file = analyze_a_file(file_path)    # NEW: Notice 2 values are returned.\n",
    "        \n",
    "        list_of_results.append(results)        # Add the results to the list of results\n",
    "        \n",
    "        list_of_words.extend(words_in_file)    # Add 'words_in_file' to 'list_of_words' \n",
    "        \n",
    "        file_count += 1\n",
    "\n",
    "    # Analyze the group\n",
    "    num_words = count_words(list_of_words)\n",
    "    ttr = get_ttr(list_of_words)        \n",
    "    \n",
    "    corpus_results = dict()\n",
    "    corpus_results['folder'] = folder\n",
    "    corpus_results['num_words'] = num_words/file_count\n",
    "    corpus_results['ttr'] = ttr\n",
    "    \n",
    "    # Save the list of results to a CSV file\n",
    "    save_results(list_of_results, corpus_results, csv_fpath)  \n",
    "    print(f\"The results are stored in {csv_fpath}\")\n",
    "\n",
    "# Test\n",
    "analyze_a_corpus(\"test/corpus\", \"test/results.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274795f9",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The following code calls the main function `analyze_a_corpus`, which uses all the other functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edb56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are stored in data/first_term.csv\n",
      "The results are stored in data/first_term.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "analyze_a_corpus(\"data/first_term\", \"data/first_term.csv\")\n",
    "analyze_a_corpus(\"data/first_term\", \"data/first_term.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab11ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9716d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
